apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: atharva-train-merge
  namespace: atharva-ml
spec:
  entrypoint: dag
  serviceAccountName: wf-runner
  podGC:
    strategy: OnWorkflowSuccess

  templates:
  - name: dag
    dag:
      tasks:
      - name: generate-data
        template: generate-data
      - name: build-index
        dependencies: [generate-data]
        template: build-index
      - name: train-lora
        dependencies: [build-index]
        template: train-lora
        arguments:
          parameters:
          - name: max-steps
            value: "{{workflow.parameters.max-steps}}"
      - name: merge-model
        dependencies: [train-lora]
        template: merge-model

  # --- Step 1: Generate synthetic training data (no heavy deps) ---
  - name: generate-data
    nodeSelector:
      kubernetes.io/hostname: llmops-kind-worker
    container:
      image: python:3.11-slim
      imagePullPolicy: IfNotPresent
      command: ["bash","-lc"]
      args:
        - |
          set -euo pipefail
          python /mnt/project/atharva-dental-assistant/tools/synth_data.py \
            --clinic Pune --currency INR \
            --treatments /mnt/project/atharva-dental-assistant/datasets/clinic/treatments.json \
            --policies /mnt/project/atharva-dental-assistant/datasets/clinic/policies/*.md \
            --faq /mnt/project/atharva-dental-assistant/datasets/clinic/faq.md \
            --recent /mnt/project/atharva-dental-assistant/datasets/clinic/recent_queries.jsonl \
            --out /mnt/project/atharva-dental-assistant/datasets/training
      volumeMounts:
      - name: host
        mountPath: /mnt/project
      resources:
        requests:
          cpu: "250m"
          memory: "512Mi"
    volumes:
    - name: host
      hostPath:
        path: /mnt/project
        type: Directory

  # --- Step 2: Build sparse TF-IDF index (lightweight, wheels-only) ---
  - name: build-index
    nodeSelector:
      kubernetes.io/hostname: llmops-kind-worker
    container:
      image: python:3.11-slim
      imagePullPolicy: IfNotPresent
      command: ["bash","-lc"]
      args:
        - |
          set -euo pipefail
          export HOME=/mnt/project
          VENV="$HOME/.venv-build"
          ROOT="$HOME/atharva-dental-assistant/datasets/clinic"
          OUT="$HOME/atharva-dental-assistant/artifacts/rag"

          python -m venv "$VENV"
          . "$VENV/bin/activate"
          python -m pip install --upgrade pip
          pip install --only-binary=:all: \
            numpy==1.26.4 scipy==1.10.1 scikit-learn==1.3.2 joblib==1.3.2

          mkdir -p "$OUT"
          python /mnt/project/atharva-dental-assistant/rag/build_index.py \
            --root "$ROOT" \
            --outdir "$OUT" \
            --backend sparse

          ls -lah "$OUT" && (wc -c "$OUT"/meta.json || true)
      volumeMounts:
      - name: host
        mountPath: /mnt/project
      resources:
        requests:
          cpu: "500m"
          memory: "1Gi"
    volumes:
    - name: host
      hostPath:
        path: /mnt/project
        type: Directory

  # --- Step 3: LoRA training (matches job-train-lora.yaml) ---
  - name: train-lora
    inputs:
      parameters:
      - name: max-steps
        value: "400"
    nodeSelector:
      kubernetes.io/hostname: llmops-kind-worker
    container:
      image: schoolofdevops/lora-build-python:3.11-slim
      imagePullPolicy: IfNotPresent
      command: ["bash","-lc"]
      args:
        - |
          set -euo pipefail
          # MAX_STEPS is read by your training script from env
          export MAX_STEPS={{inputs.parameters.max-steps}}
          python /mnt/project/atharva-dental-assistant/training/train_lora.py
          # record last run id for the next step
          RUN_DIR="$(ls -1dt /mnt/project/atharva-dental-assistant/artifacts/train/*/ | head -n 1)"
          RUN_ID="$(basename "$RUN_DIR")"
          echo "$RUN_ID" > /mnt/project/atharva-dental-assistant/artifacts/train/LAST_RUN_ID.txt
      env:
      - name: BASE_MODEL
        value: "HuggingFaceTB/SmolLM2-135M-Instruct"
      - name: MAX_SEQ_LEN
        value: "256"
      - name: LORA_R
        value: "4"
      - name: LORA_ALPHA
        value: "8"
      - name: LORA_DROPOUT
        value: "0.05"
      - name: LR
        value: "2e-4"
      - name: WARMUP_RATIO
        value: "0.02"
      - name: BATCH_SIZE
        value: "1"
      - name: GRAD_ACCUM
        value: "1"
      - name: MAX_STEPS
        value: "80"                 # default; overridden by parameter above
      - name: DEMO_MAX_TRAIN_SAMPLES
        value: "0"
      - name: DEMO_MAX_VAL_SAMPLES
        value: "0"
      - name: HF_HOME
        value: "/cache/hf"
      - name: HF_HUB_DISABLE_TELEMETRY
        value: "1"
      - name: TOKENIZERS_PARALLELISM
        value: "true"
      - name: OMP_NUM_THREADS
        value: "4"
      - name: MKL_NUM_THREADS
        value: "4"
      - name: NUMEXPR_MAX_THREADS
        value: "4"
      resources:
        requests:
          cpu: "2"
          memory: "4Gi"
          ephemeral-storage: "5Gi"
        limits:
          cpu: "4"
          memory: "6Gi"
          ephemeral-storage: "20Gi"
      volumeMounts:
      - name: host
        mountPath: /mnt/project
      - name: hf-cache
        mountPath: /cache/hf
    volumes:
    - name: host
      hostPath:
        path: /mnt/project
        type: Directory
    - name: hf-cache
      hostPath:
        path: /mnt/hf-cache
        type: DirectoryOrCreate

  # --- Step 4: Merge LoRA into base model (matches job-merge-model.yaml) ---
  - name: merge-model
    nodeSelector:
      kubernetes.io/hostname: llmops-kind-worker
    container:
      image: schoolofdevops/lora-build-python:3.11-slim
      imagePullPolicy: IfNotPresent
      command: ["bash","-lc"]
      args:
        - |
          set -euo pipefail
          # If RUN_ID not provided, read the last run id produced by previous step
          export RUN_ID="${RUN_ID:-$(tr -d ' \n' </mnt/project/atharva-dental-assistant/artifacts/train/LAST_RUN_ID.txt)}"
          echo "Merging RUN_ID=$RUN_ID"
          python /mnt/project/atharva-dental-assistant/training/merge_lora.py
      env:
      - name: BASE_MODEL
        value: "HuggingFaceTB/SmolLM2-135M-Instruct"
      # Optional: allow overriding RUN_ID from workflow params if ever needed
      # - name: RUN_ID
      #   value: "REPLACE_WITH_RUN_ID"
      volumeMounts:
      - name: host
        mountPath: /mnt/project
      resources:
        requests:
          cpu: "500m"
          memory: "2Gi"
    volumes:
    - name: host
      hostPath:
        path: /mnt/project
        type: Directory

  arguments:
    parameters:
    - name: max-steps
      value: "100"
